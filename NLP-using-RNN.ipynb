{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtvlSCb4WsZg+VmUlXVD24"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVkKjufyiJCa",
        "outputId": "924604a8-e8c4-498e-cc6a-63bfce566e38",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: {'the': 0, 'lay': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'bed': 6}\n",
            "Index: {0: 'the', 1: 'lay', 2: 'cat', 3: 'sat', 4: 'on', 5: 'mat', 6: 'bed'}\n",
            "Input Indices: [0, 2, 3, 4, 0, 5, 0, 2, 1, 4, 0, 6]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Preprocessing Data\n",
        "text = \"the cat sat on the mat the cat lay on the bed\"\n",
        "words = list(set(text.split()))\n",
        "word_to_idx = {word: i for i, word in enumerate(words)}\n",
        "idx_to_word = {i: word for i, word in enumerate(words)}\n",
        "vocab_size = len(words)\n",
        "\n",
        "print(\"Vocabulary:\", word_to_idx)\n",
        "print(\"Index:\", idx_to_word)\n",
        "# Fungsi untuk mengubah teks menjadi urutan indeks\n",
        "def text_to_indices(text):\n",
        "    return [word_to_idx[word] for word in text.split()]\n",
        "\n",
        "input_indices = text_to_indices(text)\n",
        "print(\"Input Indices:\", input_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Parameter Model\n",
        "embedding_dim = 5   # Dimensi embedding\n",
        "hidden_dim = 10     # Dimensi hidden layer\n",
        "seq_length = 4      # Panjang sequence untuk RNN\n",
        "learning_rate = 0.01\n",
        "n_epochs = 2"
      ],
      "metadata": {
        "id": "iPTtWpstiRHM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Inisialisasi Bobot\n",
        "np.random.seed(42)\n",
        "W = np.random.randn(embedding_dim, hidden_dim)\n",
        "U = np.random.randn(hidden_dim, hidden_dim)\n",
        "V = np.random.randn(hidden_dim, vocab_size)\n",
        "\n",
        "# Membuat embedding matriks\n",
        "E = np.random.randn(vocab_size, embedding_dim)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))\n",
        "    return exp_x / exp_x.sum(axis=0)\n",
        "\n",
        "def cross_entropy_loss(pred, target):\n",
        "    return -np.log(pred[target] + 1e-9)\n",
        "\n",
        "# Fungsi untuk one-hot encoding\n",
        "def one_hot_encoding(word_index, vocab_size):\n",
        "    one_hot = np.zeros(vocab_size)\n",
        "    one_hot[word_index] = 1\n",
        "    return one_hot"
      ],
      "metadata": {
        "id": "vYJzSsD1iTi9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Membuat Dataset Input dan Target\n",
        "def get_data(input_indices, seq_length):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(input_indices) - seq_length):\n",
        "        X.append(input_indices[i:i + seq_length])\n",
        "        Y.append(input_indices[i + seq_length])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "X, Y = get_data(input_indices, seq_length)\n",
        "print(\"Training Data (X):\", X)\n",
        "print(\"Training Labels (Y):\", Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVflaQMqiWfu",
        "outputId": "7f736d02-7ed4-4a7f-813b-b97ec2eb060d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data (X): [[0 2 3 4]\n",
            " [2 3 4 0]\n",
            " [3 4 0 5]\n",
            " [4 0 5 0]\n",
            " [0 5 0 2]\n",
            " [5 0 2 1]\n",
            " [0 2 1 4]\n",
            " [2 1 4 0]]\n",
            "Training Labels (Y): [0 5 0 2 1 4 0 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Implementasi RNN\n",
        "def forward(inputs, hidden_state):\n",
        "    # Inisialisasi hidden state\n",
        "    for t in range(len(inputs)):\n",
        "        x_t = E[inputs[t]]  # Mendapatkan embedding untuk kata\n",
        "        hidden_state = np.tanh(np.dot(x_t, W) + np.dot(hidden_state, U))  # Rumus hidden state\n",
        "    output = np.dot(hidden_state, V)  # Output ke ruang kosakata\n",
        "    y_pred = softmax(output)\n",
        "    return y_pred, hidden_state"
      ],
      "metadata": {
        "id": "gikQjaieiZO2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Pelatihan Model\n",
        "hidden_state = np.zeros(hidden_dim)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for i in range(len(X)):\n",
        "        inputs = X[i]\n",
        "        target = Y[i]\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred, hidden_state = forward(inputs, hidden_state)\n",
        "        #cek hasil\n",
        "        predicted_idx = np.argmax(y_pred)\n",
        "        predicted_word = idx_to_word[predicted_idx]\n",
        "        print(f\"Next word: {predicted_word}\")\n",
        "\n",
        "        # Menghitung loss\n",
        "        loss = cross_entropy_loss(y_pred, target)\n",
        "        total_loss += loss\n",
        "\n",
        "        # Backpropagation (perhitungan gradien secara manual)\n",
        "        dL_dV = np.outer(hidden_state, (y_pred - one_hot_encoding(target, vocab_size)))\n",
        "        dL_dh = np.dot(V, (y_pred - one_hot_encoding(target, vocab_size)))\n",
        "\n",
        "        dL_dU = np.zeros_like(U)\n",
        "        dL_dW = np.zeros_like(W)\n",
        "\n",
        "        # Gradient descent update untuk V\n",
        "        V -= learning_rate * dL_dV\n",
        "\n",
        "        # Backpropagation melalui waktu (BPTT)\n",
        "        for t in reversed(range(len(inputs))):\n",
        "            x_t = E[inputs[t]]\n",
        "            dL_dh_raw = dL_dh * (1 - hidden_state ** 2)\n",
        "            dL_dU += np.outer(hidden_state, dL_dh_raw)\n",
        "            dL_dW += np.outer(x_t, dL_dh_raw)\n",
        "            dL_dh = np.dot(U, dL_dh_raw)\n",
        "\n",
        "        # Update bobot\n",
        "        U -= learning_rate * dL_dU\n",
        "        W -= learning_rate * dL_dW\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {total_loss / len(X):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_Umil_jibnI",
        "outputId": "624f2b3f-8467-4923-c0bf-2dea4710002e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word: the\n",
            "Next word: bed\n",
            "Next word: mat\n",
            "Next word: bed\n",
            "Next word: sat\n",
            "Next word: sat\n",
            "Next word: the\n",
            "Next word: bed\n",
            "Next word: the\n",
            "Next word: bed\n",
            "Next word: mat\n",
            "Next word: bed\n",
            "Next word: sat\n",
            "Next word: sat\n",
            "Next word: the\n",
            "Next word: bed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Prediksi Kata Berikutnya\n",
        "def predict_next_word(model_input, n_predictions=3):\n",
        "    hidden_state = np.zeros(hidden_dim)\n",
        "    for _ in range(n_predictions):\n",
        "        y_pred, hidden_state = forward(model_input, hidden_state)\n",
        "        predicted_idx = np.argmax(y_pred)\n",
        "        predicted_word = idx_to_word[predicted_idx]\n",
        "        print(f\"Next word: {predicted_word}\")\n",
        "        model_input = np.append(model_input[1:], predicted_idx)"
      ],
      "metadata": {
        "id": "42fR53L9iekx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Tes Prediksi\n",
        "print(\"\\nPrediksi Kata Berikutnya:\")\n",
        "input_text = \"the cat sat on\"\n",
        "input_indices = text_to_indices(input_text)\n",
        "predict_next_word(input_indices[-seq_length:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDMHDdE7ih8n",
        "outputId": "352eb7e9-64cd-46eb-e013-3fb24c6a98ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediksi Kata Berikutnya:\n",
            "Next word: the\n",
            "Next word: bed\n",
            "Next word: the\n"
          ]
        }
      ]
    }
  ]
}