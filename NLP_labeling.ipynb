{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPi117P4lCjLLLzf4LoHbvb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFL4DuMiALqZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Data dan Preprocessing\n",
        "# Contoh data kalimat dan label (part-of-speech tagging)\n",
        "sentences = [\n",
        "    \"the cat sat on the mat\",\n",
        "    \"the dog lay on the bed\",\n",
        "    \"the bird flew to the tree\"\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    \"DET NOUN VERB PREP DET NOUN\",\n",
        "    \"DET NOUN VERB PREP DET NOUN\",\n",
        "    \"DET NOUN VERB PREP DET NOUN\"\n",
        "]\n",
        "\n",
        "# Membuat daftar kata unik (vocabulary) dan tag unik\n",
        "words = list(set(\" \".join(sentences).split()))\n",
        "tags = list(set(\" \".join(labels).split()))\n",
        "\n",
        "# Mapping kata dan tag ke indeks\n",
        "word_to_idx = {word: i for i, word in enumerate(words)}\n",
        "idx_to_word = {i: word for i, word in enumerate(words)}\n",
        "tag_to_idx = {tag: i for i, tag in enumerate(tags)}\n",
        "idx_to_tag = {i: tag for i, tag in enumerate(tags)}\n",
        "\n",
        "vocab_size = len(words)\n",
        "tag_size = len(tags)\n",
        "\n",
        "print(\"Vocabulary:\", word_to_idx)\n",
        "print(\"Tags:\", tag_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk mengubah teks menjadi urutan indeks\n",
        "def text_to_indices(text, word_map):\n",
        "    return [word_map[word] for word in text.split()]\n",
        "\n",
        "def labels_to_indices(label, tag_map):\n",
        "    return [tag_map[tag] for tag in label.split()]\n",
        "\n",
        "# Konversi kalimat dan label menjadi urutan indeks\n",
        "X_data = [text_to_indices(sentence, word_to_idx) for sentence in sentences]\n",
        "Y_data = [labels_to_indices(label, tag_to_idx) for label in labels]\n",
        "\n",
        "# Parameter model\n",
        "embedding_dim = 5   # Dimensi embedding\n",
        "hidden_dim = 10     # Dimensi hidden layer\n",
        "learning_rate = 0.01\n",
        "n_epochs = 200"
      ],
      "metadata": {
        "id": "godwiyksAYUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Inisialisasi Bobot\n",
        "np.random.seed(42)\n",
        "W = np.random.randn(embedding_dim, hidden_dim)\n",
        "U = np.random.randn(hidden_dim, hidden_dim)\n",
        "V = np.random.randn(hidden_dim, tag_size)\n",
        "\n",
        "# Membuat embedding matriks\n",
        "E = np.random.randn(vocab_size, embedding_dim)\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))\n",
        "    return exp_x / exp_x.sum(axis=0)\n",
        "\n",
        "def cross_entropy_loss(pred, target):\n",
        "    return -np.log(pred[target] + 1e-9)\n",
        "\n",
        "# Fungsi untuk one-hot encoding\n",
        "def one_hot_encoding(index, size):\n",
        "    one_hot = np.zeros(size)\n",
        "    one_hot[index] = 1\n",
        "    return one_hot"
      ],
      "metadata": {
        "id": "3aZwj0v8AZBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. RNN Forward Pass dan Backpropagation\n",
        "def forward(inputs):\n",
        "    hidden_state = np.zeros(hidden_dim)\n",
        "    outputs = []\n",
        "    hidden_states = []\n",
        "    for t in range(len(inputs)):\n",
        "        x_t = E[inputs[t]]\n",
        "        hidden_state = np.tanh(np.dot(x_t, W) + np.dot(hidden_state, U))\n",
        "        output = np.dot(hidden_state, V)\n",
        "        y_pred = softmax(output)\n",
        "        outputs.append(y_pred)\n",
        "        hidden_states.append(hidden_state)\n",
        "    return outputs, hidden_states"
      ],
      "metadata": {
        "id": "8MeRZ9f9Ab47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Pelatihan Model\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for i in range(len(X_data)):\n",
        "        inputs = X_data[i]\n",
        "        targets = Y_data[i]\n",
        "\n",
        "        # Forward pass\n",
        "        y_preds, hidden_states = forward(inputs)\n",
        "\n",
        "        # Backpropagation (perhitungan gradien secara manual)\n",
        "        dL_dV = np.zeros_like(V)\n",
        "        dL_dU = np.zeros_like(U)\n",
        "        dL_dW = np.zeros_like(W)\n",
        "        dL_dh = np.zeros(hidden_dim)\n",
        "\n",
        "        for t in reversed(range(len(inputs))):\n",
        "            y_pred = y_preds[t]\n",
        "            target = targets[t]\n",
        "            hidden_state = hidden_states[t]\n",
        "\n",
        "            # Gradien output layer V\n",
        "            error = y_pred - one_hot_encoding(target, tag_size)\n",
        "            dL_dV += np.outer(hidden_state, error)\n",
        "\n",
        "            # Gradien terhadap hidden state\n",
        "            dL_dh = np.dot(V, error) * (1 - hidden_state ** 2)\n",
        "\n",
        "            # Backpropagate ke U dan W\n",
        "            x_t = E[inputs[t]]\n",
        "            dL_dU += np.outer(hidden_states[t - 1] if t > 0 else np.zeros(hidden_dim), dL_dh)\n",
        "            dL_dW += np.outer(x_t, dL_dh)\n",
        "\n",
        "        # Update bobot\n",
        "        V -= learning_rate * dL_dV\n",
        "        U -= learning_rate * dL_dU\n",
        "        W -= learning_rate * dL_dW\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {total_loss / len(X_data):.4f}\")"
      ],
      "metadata": {
        "id": "LtuCSbzFAeQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Prediksi Label untuk Kalimat\n",
        "def predict_labels(sentence):\n",
        "    inputs = text_to_indices(sentence, word_to_idx)\n",
        "    y_preds, _ = forward(inputs)\n",
        "    predicted_tags = [idx_to_tag[np.argmax(y_pred)] for y_pred in y_preds]\n",
        "    return predicted_tags\n",
        "\n",
        "# Tes Prediksi\n",
        "test_sentence = \"the cat sat on\"\n",
        "print(f\"\\nInput: '{test_sentence}'\")\n",
        "predicted_tags = predict_labels(test_sentence)\n",
        "print(\"Predicted Tags:\", predicted_tags)"
      ],
      "metadata": {
        "id": "QbbzDxWgAiZe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}