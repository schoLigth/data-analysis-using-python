{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8lTrfBD0Q_f"
      },
      "source": [
        "# Collaborative Filtering - Item Based Recommender Systems\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB13Euos2oSp"
      },
      "source": [
        "# 1. Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdP70zB02thl"
      },
      "source": [
        "## Load books data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYNmldJz1CfI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mDhJyAPeBTM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "df_books1 = pd.read_csv('/content/drive/MyDrive/Sistem Rekomendasi/books.csv')\n",
        "df_books1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bphA1aL2xNJ"
      },
      "source": [
        "# 2. Eksploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvggTCi21Mee"
      },
      "outputs": [],
      "source": [
        "df_books1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vJtmtTtqyOK1"
      },
      "outputs": [],
      "source": [
        "df_books = pd.read_csv(\"/content/drive/MyDrive/Sistem Rekomendasi/books.csv\",\n",
        "                 usecols=[\"book_id\",\n",
        "                          \"original_publication_year\",\n",
        "                          \"title\",\n",
        "                          \"average_rating\"])\n",
        "df_books.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vIHSz-c1RTd"
      },
      "outputs": [],
      "source": [
        "df_books.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsvBvTBS25jE"
      },
      "source": [
        "## Check missing values of books"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiuZN5OB0-cP"
      },
      "source": [
        "program dibawah digunakan untuk mendeteksi jumlah nilai yang hilang (missing values) pada setiap kolom dalam DataFrame df_books."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiMsaqUN2XVS"
      },
      "outputs": [],
      "source": [
        "missing_values1 = df_books.isnull().sum()\n",
        "\n",
        "missing_values1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoXuBU8S5PYK"
      },
      "outputs": [],
      "source": [
        "# Hitung jumlah nilai unik dalam setiap kolom DataFrame df_books\n",
        "jumlah_nilai_unik = df_books.nunique()\n",
        "print(jumlah_nilai_unik)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "awtUrP4v7acW"
      },
      "outputs": [],
      "source": [
        "# # Menampilkan semua nilai unik beserta jumlah kata unik dan frekuensinya\n",
        "# for col in df_books.columns:\n",
        "#     print(f\"Kolom: {col}\")\n",
        "\n",
        "#     # Mengambil nilai unik di kolom\n",
        "#     unique_values = df_books[col].unique()\n",
        "\n",
        "#     # Menampilkan nilai unik\n",
        "#     print(\"Nilai unik:\")\n",
        "#     print(unique_values)\n",
        "\n",
        "#     # Menampilkan jumlah kata unik (untuk tipe object, berdasarkan spasi)\n",
        "#     if df_books[col].dtype == 'object':\n",
        "#         word_counts = [len(str(value).split()) for value in unique_values]\n",
        "#         print(\"Jumlah kata untuk tiap nilai unik:\")\n",
        "#         print(word_counts)\n",
        "\n",
        "#     # Menampilkan jumlah total nilai unik\n",
        "#     print(f\"Jumlah nilai unik: {len(unique_values)}\")\n",
        "\n",
        "#     # Menampilkan frekuensi masing-masing nilai unik\n",
        "#     print(\"Frekuensi nilai unik:\")\n",
        "#     print(df_books[col].value_counts())\n",
        "\n",
        "#     print(\"\\n\",\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sLWjpDV28v5"
      },
      "source": [
        "## Load rating data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf-iiGQzyP0c"
      },
      "outputs": [],
      "source": [
        "df_rating = pd.read_csv(\"/content/drive/MyDrive/Sistem Rekomendasi/ratings.csv\",\n",
        "            usecols=[\"book_id\", \"user_id\", \"rating\"])\n",
        "\n",
        "df_rating.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvkdpcPE3BM6"
      },
      "source": [
        "## Print rating information and missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUzlskvG2F7s"
      },
      "outputs": [],
      "source": [
        "#digunakan untuk menampilkan ringkasan informasi mengenai struktur DataFrame df_rating yang telah dimuat dari file CSV\n",
        "df_rating.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9R_u-kRyvWI"
      },
      "outputs": [],
      "source": [
        "#untuk mendeteksi jumlah nilai yang hilang (missing values) dalam DataFrame df_rating, yang berisi data rating buku.\n",
        "missing_values2 = df_rating.isnull().sum()\n",
        "\n",
        "missing_values2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DSlIuBvs8Zwo"
      },
      "outputs": [],
      "source": [
        "# # Menampilkan semua nilai unik beserta jumlah kata unik dan frekuensinya\n",
        "# for col in df_rating.columns:\n",
        "#     print(f\"Kolom: {col}\")\n",
        "\n",
        "#     # Mengambil nilai unik di kolom\n",
        "#     unique_values = df_rating[col].unique()\n",
        "\n",
        "#     # Menampilkan nilai unik\n",
        "#     print(\"Nilai unik:\")\n",
        "#     print(unique_values)\n",
        "\n",
        "#     # Menampilkan jumlah kata unik (untuk tipe object, berdasarkan spasi)\n",
        "#     if df_rating[col].dtype == 'object':\n",
        "#         word_counts = [len(str(value).split()) for value in unique_values]\n",
        "#         print(\"Jumlah kata untuk tiap nilai unik:\")\n",
        "#         print(word_counts)\n",
        "\n",
        "#     # Menampilkan jumlah total nilai unik\n",
        "#     print(f\"Jumlah nilai unik: {len(unique_values)}\")\n",
        "\n",
        "#     # Menampilkan frekuensi masing-masing nilai unik\n",
        "#     print(\"Frekuensi nilai unik:\")\n",
        "#     print(df_rating[col].value_counts())\n",
        "\n",
        "#     print(\"\\n\",\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omEvUEGT3JfR"
      },
      "source": [
        "# 3. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYma1vye9YV_"
      },
      "source": [
        "## Clean dataset\n",
        "\n",
        "program dibawah digunakan untuk menghapus baris yang mengandung nilai kosong (missing values) dalam DataFrame df_books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO446CPKyyD8"
      },
      "outputs": [],
      "source": [
        "# hapus baris yang mengandung nilai kosong (missing values) dalam DataFrame df_books\n",
        "df_books_cleaned = df_books.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHmYndcgy11q"
      },
      "outputs": [],
      "source": [
        "df_books_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vD-F9J73eue"
      },
      "outputs": [],
      "source": [
        "df_books_cleaned.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuMLISan9bMp"
      },
      "source": [
        "## Merge dataset books and rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgGpLNzj46dW"
      },
      "source": [
        "program dibawah  digunakan untuk menggabungkan dua DataFrame (df_books_cleaned dan df_rating) berdasarkan kolom yang sama, yaitu book_id, dengan menggunakan metode inner join."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DqF5Iumy3SW"
      },
      "outputs": [],
      "source": [
        "df = pd.merge(df_books_cleaned, df_rating, on=\"book_id\", how=\"inner\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xen_sCH1BxAG"
      },
      "source": [
        "Inner Join:\n",
        "- Hanya peduli pada data yang cocok antara kedua tabel.\n",
        "- Menampilkan hanya buku yang memiliki rating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noTTLKuf9iXk"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDW_-Yjj9GYa"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pW_36-s57jw"
      },
      "source": [
        "program dibawah digunakan untuk menghitung jumlah kemunculan (frekuensi) masing-masing nilai unik dalam kolom book_id dari DataFrame df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TuVFEDLly5M5"
      },
      "outputs": [],
      "source": [
        "# df[\"book_id\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sy_bx7i-83lC"
      },
      "outputs": [],
      "source": [
        "# Menampilkan semua nilai unik beserta jumlah kata unik dan frekuensinya\n",
        "for col in df.columns:\n",
        "    print(f\"Kolom: {col}\")\n",
        "\n",
        "    # Mengambil nilai unik di kolom\n",
        "    unique_values = df[col].unique()\n",
        "\n",
        "    # Menampilkan nilai unik\n",
        "    print(\"Nilai unik:\")\n",
        "    print(unique_values)\n",
        "\n",
        "    # Menampilkan jumlah kata unik (untuk tipe object, berdasarkan spasi)\n",
        "    if df[col].dtype == 'object':\n",
        "        word_counts = [len(str(value).split()) for value in unique_values]\n",
        "        print(\"Jumlah kata untuk tiap nilai unik:\")\n",
        "        print(word_counts)\n",
        "\n",
        "    # Menampilkan jumlah total nilai unik\n",
        "    print(f\"Jumlah nilai unik: {len(unique_values)}\")\n",
        "\n",
        "    # Menampilkan frekuensi masing-masing nilai unik\n",
        "    print(\"Frekuensi nilai unik:\")\n",
        "    # print(df[col].value_counts())\n",
        "\n",
        "    # print(\"\\n\",\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ4ELgnR5TuJ"
      },
      "outputs": [],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo9NLzQN6IE5"
      },
      "outputs": [],
      "source": [
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRaCiyYs845c"
      },
      "outputs": [],
      "source": [
        "# Cek duplikasi pada kombinasi user_id dan title\n",
        "print(df.duplicated(subset=[\"user_id\", \"title\"]).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwGHjUoc88x5"
      },
      "outputs": [],
      "source": [
        "# Hapus duplikasi\n",
        "df = df.drop_duplicates(subset=[\"user_id\", \"title\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0-Fo4qD9ady"
      },
      "outputs": [],
      "source": [
        "# Periksa apakah rating benar-benar memiliki nilai untuk kombinasi user_id dan title\n",
        "print(df[df[\"user_id\"] == 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VMIYZ7W92aI"
      },
      "outputs": [],
      "source": [
        "# Periksa tipe data\n",
        "print(df.dtypes)\n",
        "\n",
        "# Periksa nilai unik dari kolom penting\n",
        "print(df[\"title\"].unique()[:10])  # Periksa beberapa judul buku\n",
        "print(df[\"rating\"].unique())     # Periksa nilai rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6nxiXELt-M3V"
      },
      "outputs": [],
      "source": [
        "# Periksa contoh nilai untuk user_id tertentu\n",
        "print(df[df[\"user_id\"] == 2])  # Ganti dengan user_id yang relevan\n",
        "\n",
        "# Periksa total rating per user\n",
        "# print(df.groupby(\"user_id\")[\"rating\"].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YFgpTiQUWIu",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Hitung jumlah rating per user\n",
        "rating_counts = df['user_id'].value_counts()\n",
        "\n",
        "# Filter user_id dengan lebih dari 5 rating\n",
        "valid_users = rating_counts[rating_counts > 5].index\n",
        "\n",
        "# Filter dataset hanya untuk valid user_id\n",
        "filtered_df = df[df['user_id'].isin(valid_users)]\n",
        "\n",
        "# Tampilkan hasil\n",
        "# filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1qCPcGcEzyO"
      },
      "outputs": [],
      "source": [
        "# Menampilkan seluruh dataset yang akan digunakan sebelum grouping\n",
        "# Salin dataframe untuk manipulasi sementara\n",
        "df_temp = df.copy()\n",
        "\n",
        "# Potong kolom 'title' agar hanya menampilkan kata pertama\n",
        "df_temp[\"title\"] = df_temp[\"title\"].str.split().str[:3]\n",
        "\n",
        "# Tampilkan seluruh dataset tanpa batasan baris/kolom\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "# Cetak dataframe\n",
        "df_temp.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp.info()"
      ],
      "metadata": {
        "id": "CG-9_WwmAHXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asumsi df adalah dataframe Anda yang berisi data buku dan rating\n",
        "# Filter data untuk rating >= 1\n",
        "filtered_df = df[df['rating'] >= 1]\n",
        "\n",
        "# Hitung jumlah rating untuk setiap buku\n",
        "rating_counts = filtered_df.groupby('title').size()\n",
        "\n",
        "# Urutkan berdasarkan jumlah rating secara descending\n",
        "sorted_rating_counts = rating_counts.sort_values(ascending=False)\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(sorted_rating_counts.head(10))  # Menampilkan 10 buku dengan rating terbanyak\n",
        "print(sorted_rating_counts.tail(10))  # Menampilkan 10 buku dengan rating terbanyak"
      ],
      "metadata": {
        "id": "kUFmFv9RBnA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asumsi df adalah dataframe Anda yang berisi data buku dan rating\n",
        "# Filter data untuk rating >= 1\n",
        "filtered_df = df[df['rating'] >= 1]\n",
        "\n",
        "# Hitung jumlah rating untuk setiap buku\n",
        "rating_counts = filtered_df.groupby('user_id').size()\n",
        "\n",
        "# Urutkan berdasarkan jumlah rating secara descending\n",
        "sorted_rating_counts = rating_counts.sort_values(ascending=False)\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(sorted_rating_counts.head(10))  # Menampilkan 10 buku dengan rating terbanyak\n",
        "print(sorted_rating_counts.tail(10))  # Menampilkan 10 buku dengan rating terbanyak"
      ],
      "metadata": {
        "id": "LUINnVmCC3Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5X-TBULRy9r"
      },
      "outputs": [],
      "source": [
        "# Hitung jumlah rating per user\n",
        "rating_counts = df['user_id'].value_counts()\n",
        "\n",
        "# Filter user_id dengan lebih dari 10 rating\n",
        "valid_users = rating_counts[rating_counts >= 10].index\n",
        "\n",
        "# Filter dataset hanya untuk valid user_id\n",
        "filtered_df = df[df['user_id'].isin(valid_users)]\n",
        "\n",
        "# Tampilkan hasil\n",
        "filtered_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ugXCUyZIN9L"
      },
      "outputs": [],
      "source": [
        "# Cek duplikasi pada kombinasi user_id dan title\n",
        "print(filtered_df.duplicated(subset=[\"user_id\", \"title\"]).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6oCG3-kNkT2"
      },
      "outputs": [],
      "source": [
        "filtered_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqYOQfSHOGYL"
      },
      "outputs": [],
      "source": [
        "filtered_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRPNqG38OJ1r"
      },
      "outputs": [],
      "source": [
        "filtered_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dW_idt9XB_j"
      },
      "outputs": [],
      "source": [
        "filtered_df.head()\n",
        "print(f\"Jumlah user unik: {filtered_df['user_id'].nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFFZkv-xXW5m"
      },
      "outputs": [],
      "source": [
        "print(rating_counts.describe())  # Lihat distribusi jumlah rating per user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF6IVkh2Mskj"
      },
      "source": [
        "Data sudah digabungkan, sudah dibersihkan dari data duplikat. Sehingga, sekarang dapat membentuk data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUn7_jdl9ywm"
      },
      "source": [
        "## Group dataset dengan pivot\n",
        "\n",
        "Untuk item-based collaborative filtering, pendekatan terbaik adalah menggunakan pivot. Alasannya adalah bahwa metode ini membutuhkan matriks item-user (atau matriks user-item tergantung pada pendekatan) di mana:\n",
        "\n",
        "Baris adalah item (misalnya, title buku).\n",
        "Kolom adalah user (user_id).\n",
        "Isi matriks adalah rating yang diberikan oleh user terhadap item.\n",
        "Mengapa Pivot?\n",
        "Format Matriks Diperlukan: Item-based filtering menghitung kemiripan antara item, jadi kita membutuhkan matriks di mana item menjadi fokus utama (bukan user)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfCE5iOYZ5tu"
      },
      "outputs": [],
      "source": [
        "# Pivot data\n",
        "pivot_df = filtered_df.pivot(index='user_id', columns='title', values='rating')\n",
        "\n",
        "# Isi NaN dengan 0\n",
        "pivot_df = pivot_df.fillna(0)\n",
        "\n",
        "# Tampilkan hasil\n",
        "pivot_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rPmjuDmpLP2u"
      },
      "outputs": [],
      "source": [
        "# pivot_df.notnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2atMGQw37Yj"
      },
      "outputs": [],
      "source": [
        "pivot_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "368vgM6M9_64"
      },
      "source": [
        "1. df.groupby([\"user_id\", \"title\"])[\"rating\"].mean():Mengelompokkan data berdasarkan pasangan user_id dan title (misalnya film, produk, atau item lainnya).\n",
        "Menghitung rata-rata nilai rating untuk setiap pasangan user_id dan title.\n",
        "\n",
        "2. unstack():Mengubah hasil pengelompokan menjadi format matriks atau pivot table.\n",
        "Baris akan menjadi user_id dan kolom akan menjadi title.\n",
        "Setiap sel akan diisi dengan nilai rata-rata rating, jika tersedia.\n",
        "\n",
        "3. notnull():Mengubah nilai dalam matriks menjadi nilai Boolean:\n",
        "True jika pengguna memberikan rating untuk item tertentu (nilai tidak null).\n",
        "False jika pengguna belum memberikan rating (nilai null).\n",
        "\n",
        "4. Hasil Akhir (user_df):user_df adalah matriks Boolean yang menunjukkan hubungan antara pengguna dan item:\n",
        "Baris adalah user_id.\n",
        "Kolom adalah title.\n",
        "Nilai True menunjukkan bahwa pengguna tersebut telah memberikan rating untuk item tertentu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWtUu2SW-as-"
      },
      "outputs": [],
      "source": [
        "pivot_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBAJBqBVBzg_"
      },
      "source": [
        "# 4. Modelling Item-Based Recommender System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OarPjireNUnP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Pisahkan data set training dan test\n",
        "train_df, test_df = train_test_split(pivot_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Validasi indeks sama pada test dan train\n",
        "train_df = train_df.copy()\n",
        "test_df = test_df.copy()\n",
        "test_df = test_df.where(train_df.isnull(), np.nan)\n",
        "\n",
        "print(\"Train Data Shape:\", train_df.shape)\n",
        "print(\"Test Data Shape:\", test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "P0zCYjXpQU4r"
      },
      "outputs": [],
      "source": [
        "# Hitung kemiripan item book menggunakan Cosine Similarity\n",
        "item_similarity = cosine_similarity(train_df.T.fillna(0))\n",
        "item_similarity_df = pd.DataFrame(item_similarity,\n",
        "                                   index=train_df.columns,\n",
        "                                   columns=train_df.columns)\n",
        "\n",
        "# print(item_similarity_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjZ1NPrFhXb7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Heatmap untuk item similarity\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(item_similarity_df.iloc[:20, :20], cmap='coolwarm', annot=False)\n",
        "plt.title(\"Heatmap Kemiripan Item (Cosine Similarity)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pilih top-N neighbor\n",
        "def get_top_neighbors(item_similarity_df, item, n=10):\n",
        "    return item_similarity_df[item].nlargest(n + 1).iloc[1:].index"
      ],
      "metadata": {
        "id": "bVuowNoZKBX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rating(user, item, top_n=10):\n",
        "    # Dapatkan tetangga terdekat\n",
        "    neighbors = get_top_neighbors(item_similarity_df, item, n=top_n)\n",
        "\n",
        "    # Hitung numerator dan denominator\n",
        "    numerator = sum(\n",
        "        item_similarity_df[item][neighbor] * train_df.loc[user, neighbor]\n",
        "        for neighbor in neighbors\n",
        "        if not np.isnan(train_df.loc[user, neighbor])\n",
        "    )\n",
        "    denominator = sum(\n",
        "        abs(item_similarity_df[item][neighbor])\n",
        "        for neighbor in neighbors\n",
        "        if not np.isnan(train_df.loc[user, neighbor])\n",
        "    )\n",
        "\n",
        "    # Default fallback jika denominator 0\n",
        "    if denominator == 0 or np.isnan(numerator):\n",
        "        return train_df.mean().mean()  # Gunakan rata-rata global sebagai fallback\n",
        "\n",
        "    return numerator / denominator"
      ],
      "metadata": {
        "id": "hq1tU7wVQXxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIdtscHGQUxb"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk memberikan rekomendasi berdasarkan judul buku yang dipilih, termasuk tingkat kemiripan\n",
        "def recommend_similar_books(selected_book, n_recommendations):\n",
        "    # Pastikan buku ada dalam dataset\n",
        "    if selected_book not in item_similarity_df.index:\n",
        "        print(f\"Buku '{selected_book}' tidak ditemukan dalam dataset.\")\n",
        "        return pd.DataFrame(columns=[\"Judul\", \"Tingkat Kemiripan\"])\n",
        "\n",
        "    # Ambil kemiripan buku dengan semua buku lainnya\n",
        "    similar_books = item_similarity_df[selected_book]\n",
        "\n",
        "    # Urutkan berdasarkan kemiripan (descending), lalu ambil top-N\n",
        "    top_recommendations = similar_books.sort_values(ascending=False).iloc[1:n_recommendations+1]\n",
        "\n",
        "    # Konversi ke DataFrame\n",
        "    recommendations_df = pd.DataFrame({\n",
        "        \"Judul\": top_recommendations.index,\n",
        "        \"Tingkat Kemiripan\": top_recommendations.values\n",
        "    })\n",
        "    return recommendations_df\n",
        "\n",
        "# Cari buku\n",
        "selected_book = \"A Briefer History of Time\"\n",
        "recommendations_by_book = recommend_similar_books(selected_book, n_recommendations=10)\n",
        "\n",
        "# Hasil rekomendasi\n",
        "print(f\"Rekomendasi berdasarkan buku '{selected_book}':\")\n",
        "print(recommendations_by_book)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeZsQlyTinfs"
      },
      "source": [
        "# Evaluation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_27oQ0uvQUqj"
      },
      "outputs": [],
      "source": [
        "# Evaluasi dengan NDCG\n",
        "def ndcg_at_k(ratings_true, ratings_pred, k=10):\n",
        "    ratings_true = np.asarray(ratings_true)[:k]\n",
        "    ratings_pred = np.asarray(ratings_pred)[:k]\n",
        "    dcg = np.sum(ratings_true / np.log2(np.arange(2, ratings_true.size + 2)))\n",
        "    ideal_dcg = np.sum(sorted(ratings_true, reverse=True) / np.log2(np.arange(2, ratings_true.size + 2)))\n",
        "    return dcg / ideal_dcg if ideal_dcg > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFpdjDJbRVJH"
      },
      "outputs": [],
      "source": [
        "# Evaluasi pada train set\n",
        "train_ndcg_scores = []\n",
        "for user in train_df.index:\n",
        "    true_ratings = train_df.loc[user].fillna(0).values\n",
        "    predicted_ratings = [predict_rating(user, item) for item in train_df.columns]\n",
        "    train_ndcg_scores.append(ndcg_at_k(true_ratings, predicted_ratings, k=5))\n",
        "\n",
        "print(f\"Rata-rata NDCG pada Train Set: {np.mean(train_ndcg_scores):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlMxM1r4hmii"
      },
      "outputs": [],
      "source": [
        "# Histogram rating pada train set\n",
        "plt.figure(figsize=(8, 5))\n",
        "train_ratings = train_df.stack()\n",
        "plt.hist(train_ratings, bins=20, color='blue', alpha=0.7)\n",
        "plt.title(\"Distribusi Rating pada Train Set\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Frekuensi\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUDgp8LPRVN7"
      },
      "outputs": [],
      "source": [
        "common_users = test_df.index.intersection(train_df.index)\n",
        "test_ndcg_scores = []\n",
        "for user in common_users:\n",
        "    # Ambil rating aktual\n",
        "    true_ratings = test_df.loc[user].fillna(0).values\n",
        "\n",
        "    # Hitung prediksi rating\n",
        "    predicted_ratings = [\n",
        "        predict_rating(user, item) if not np.isnan(test_df.loc[user, item]) else 0\n",
        "        for item in test_df.columns\n",
        "    ]\n",
        "\n",
        "    # Hitung NDCG jika ada prediksi valid\n",
        "    if np.any(predicted_ratings):  # Prediksi harus ada (tidak semua nol)\n",
        "        test_ndcg_scores.append(ndcg_at_k(true_ratings, predicted_ratings, k=5))\n",
        "\n",
        "# Jika test_ndcg_scores kosong, beri fallback nilai kecil\n",
        "if len(test_ndcg_scores) > 0:\n",
        "    print(f\"Rata-rata NDCG pada Test Set: {np.mean(test_ndcg_scores):.4f}\")\n",
        "else:\n",
        "    print(\"Rata-rata NDCG pada Test Set: 0.0001 (default nilai minimal)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJ0MCdJUQLzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oqj_8bEx9-_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhJ2m3F49_Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "10fVUSlg9_Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qD_KoMWI9_IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uW_O1U_A9_NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hitung prediksi rating berdasarkan top n\n",
        "# def predict_rating(user, item, top_n=10):\n",
        "#     neighbors = get_top_neighbors(item_similarity_df, item, n=top_n)\n",
        "#     numerator = sum(item_similarity_df[item][neighbor] * train_df.loc[user, neighbor]\n",
        "#                     for neighbor in neighbors\n",
        "#                     if not np.isnan(train_df.loc[user, neighbor]))\n",
        "#     denominator = sum(abs(item_similarity_df[item][neighbor])\n",
        "#                       for neighbor in neighbors\n",
        "#                       if not np.isnan(train_df.loc[user, neighbor]))\n",
        "#     return numerator / denominator if denominator != 0 else 0"
      ],
      "metadata": {
        "id": "1dYuRTEr9_P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbnXvss4j3Ed"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Pisahkan data menjadi training dan test set\n",
        "train_data, test_data = train_test_split(pivot_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hitung kesamaan antar item pada data training\n",
        "item_similarity = cosine_similarity(train_data.T)\n",
        "item_similarity_df = pd.DataFrame(item_similarity, index=train_data.columns, columns=train_data.columns)\n",
        "\n",
        "def get_top_n_neighbors(similarity_df, item, n=2):\n",
        "    similar_items = similarity_df[item].sort_values(ascending=False)[1:n+1]\n",
        "    return similar_items\n",
        "\n",
        "def predict_rating(user_id, item, train_data, item_similarity_df, n=2):\n",
        "    similar_items = get_top_n_neighbors(item_similarity_df, item, n)\n",
        "    similar_ratings = train_data.loc[user_id, similar_items.index].dropna()\n",
        "    if not similar_ratings.empty:\n",
        "        predicted_rating = similar_ratings.mean()\n",
        "    else:\n",
        "        predicted_rating = train_data[item].mean()  # Gunakan rata-rata keseluruhan jika tidak ada tetangga yang valid\n",
        "    return predicted_rating\n",
        "\n",
        "def calculate_mse(data, item_similarity_df, n=2):\n",
        "    errors = []\n",
        "    for user_id in data.index:\n",
        "        for item in data.columns:\n",
        "            if pd.notna(data.loc[user_id, item]):\n",
        "                actual_rating = data.loc[user_id, item]\n",
        "                predicted_rating = predict_rating(user_id, item, data, item_similarity_df, n)\n",
        "                errors.append((actual_rating - predicted_rating) ** 2)\n",
        "    mse = np.mean(errors)\n",
        "    return mse\n",
        "\n",
        "# Contoh penggunaan: rekomendasi buku berdasarkan buku yang dipilih\n",
        "book_name = \"'Tis (Frank McCourt, #2)\"\n",
        "recommendations = get_book_recommendations(book_name, train_data, item_similarity_df)\n",
        "print(\"Recommendations for:\", book_name)\n",
        "print(recommendations)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COvQi6tTj3KS"
      },
      "outputs": [],
      "source": [
        "# Evaluasi model pada set training\n",
        "training_mse = calculate_mse(train_data, item_similarity_df, n=2)\n",
        "print(\"Training set MSE:\", training_mse)\n",
        "\n",
        "# Evaluasi model pada set test\n",
        "test_mse = calculate_mse(test_data, item_similarity_df, n=2)\n",
        "print(\"Test set MSE:\", test_mse)\n",
        "\n",
        "# Visualisasi data\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(pivot_df.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Missing Data Heatmap')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(pivot_df.values.flatten(), bins=50, kde=True)\n",
        "plt.title('Rating Distribution')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAaQRnwuj3Oo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCnB2Yu9j3Ry"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmK3okhCj3VI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N2R8CaIjH8_"
      },
      "source": [
        "# Model II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afBebNEr_RJw"
      },
      "source": [
        "1. pd.Series(user_df.columns): Mengubah nama kolom pada user_df (misalnya, daftar judul buku atau item) menjadi sebuah objek pd.Series, yang merupakan struktur data satu dimensi seperti daftar.\n",
        "\n",
        "2. sample(1, random_state=42): Memilih satu elemen secara acak dari objek pd.Series.\n",
        "Parameter 1 menunjukkan bahwa hanya satu elemen yang akan dipilih.\n",
        "random_state=42 memastikan hasil acak bersifat deterministik (hasil yang sama setiap kali kode dijalankan), sehingga uji coba dapat direproduksi.\n",
        "\n",
        "3. values[0]: Mengambil nilai yang dipilih dari pd.Series dalam format numpy array.\n",
        "values[0] mengambil elemen pertama dari hasil acak (karena hanya satu elemen yang dipilih).\n",
        "\n",
        "4. Hasil Akhir (random_book): Variabel random_book akan berisi nama kolom (judul item) yang dipilih secara acak dari user_df."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcainTUxBK2w"
      },
      "source": [
        "## Count correlations user_df between book_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yVpsTPw-y_Wt"
      },
      "outputs": [],
      "source": [
        "# 3. **Rekomendasi Buku**\n",
        "selected_book = \"Tis (Frank McCourt, #2)\"  # Buku pilihan\n",
        "recommendations = get_recommendations(train_filled, selected_book)\n",
        "print(\"Rekomendasi Buku Berdasarkan Buku yang Dipilih:\")\n",
        "print(recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvMSMPIGN_yc"
      },
      "outputs": [],
      "source": [
        "# 4. **Evaluasi Model pada Dataset Training**\n",
        "def evaluate_model(data, pivot_data):\n",
        "    # Hitung error hanya pada nilai non-zero\n",
        "    predictions = pivot_data.corrwith(data.mean(axis=0), axis=0)\n",
        "    mse = mean_squared_error(data.stack(), predictions.stack())\n",
        "    rmse = np.sqrt(mse)\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHjHn3R57PHD"
      },
      "source": [
        "1. random_book:\n",
        "Variabel random_book berisi nama salah satu kolom di DataFrame user_df, yaitu salah satu judul buku yang ada di dataset.\n",
        "Variabel ini kemungkinan didefinisikan sebelumnya dengan sebuah nilai seperti nama buku tertentu, atau dipilih secara acak menggunakan fungsi seperti random.choice()\n",
        "2. user_df[random_book]:\n",
        "Mengambil kolom di DataFrame user_df dengan nama sesuai nilai dari random_book.\n",
        "3. book_name:\n",
        "Variabel book_name menyimpan hasil pengambilan kolom tersebut, yaitu Series berisi informasi interaksi pengguna dengan buku.\n",
        "4. book_name (dalam konteks):\n",
        "Menampilkan hasil (interaksi pengguna dengan buku tertentu).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxuY-2eACykg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df['rating'], bins=30, kde=True)\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JEvvM_mBkiZ"
      },
      "source": [
        "1. book_name = user_df[random_book]:\n",
        "- random_book adalah nama kolom (judul buku atau item) yang telah dipilih secara acak sebelumnya.\n",
        "- user_df[random_book] mengambil kolom dari user_df yang berisi data Boolean (True/False) tentang apakah seorang pengguna memberikan rating pada buku tersebut.\n",
        "- Variabel book_name menyimpan data tentang pengguna yang telah memberikan rating pada item random_book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j0T6DrLCjlT"
      },
      "outputs": [],
      "source": [
        "pivot_df.corrwith(book_name).sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UvALwlcCuLS"
      },
      "source": [
        "2. user_df.corrwith(book_name):\n",
        "- user_df.corrwith() digunakan untuk menghitung korelasi pairwise antara semua kolom dalam user_df dengan kolom book_name.\n",
        "- Dalam konteks ini, korelasi dihitung untuk setiap kolom (item) terhadap random_book.\n",
        "- Metode korelasi default adalah Pearson Correlation, yang mengukur kesamaan pola (nilai True/False) antar item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfAhcRXpDFBm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(df_books['average_rating'], bins=30, kde=True)\n",
        "plt.title('Distribution of Average Ratings per Book')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjGIw5l3Brbu"
      },
      "source": [
        "## Count Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ss8pMW4ezAuP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Hitung kemiripan antar item (buku) menggunakan cosine similarity\n",
        "item_similarity = cosine_similarity(pivot_df.T)  # Transpose karena kita ingin item sebagai baris\n",
        "\n",
        "# Konversi hasil similarity ke dalam DataFrame agar mudah dibaca\n",
        "item_similarity_df = pd.DataFrame(item_similarity, index=pivot_df.columns, columns=pivot_df.columns)\n",
        "\n",
        "# Tampilkan sebagian hasil kemiripan antar item\n",
        "item_similarity_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ll0QSBAh4XR"
      },
      "outputs": [],
      "source": [
        "# Pilih satu buku sebagai referensi dan tampilkan kemiripan dengan buku lain\n",
        "\n",
        "similarity_with_book = item_similarity_df[random_book]\n",
        "\n",
        "# Tampilkan hasil dalam bentuk DataFrame dengan title dan kemiripannya\n",
        "similarity_df = pd.DataFrame({\n",
        "    'title': similarity_with_book.index,\n",
        "    'similarity_score': similarity_with_book.values\n",
        "})\n",
        "\n",
        "# Urutkan berdasarkan kemiripan tertinggi\n",
        "similarity_df = similarity_df.sort_values(by='similarity_score', ascending=False)\n",
        "\n",
        "# Tampilkan tabel hasil kemiripan\n",
        "print(similarity_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8x8tmTOibVt"
      },
      "source": [
        "## Prediksi Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BuV8dsTie4m"
      },
      "outputs": [],
      "source": [
        "def predict_ratings(user_id, pivot_df, item_similarity_df):\n",
        "    user_ratings = pivot_df.loc[user_id]\n",
        "    predicted_ratings = {}\n",
        "\n",
        "    for item in pivot_df.columns:\n",
        "        if user_ratings[item] == 0:  # Hanya prediksi untuk item yang belum diberi rating\n",
        "            similar_items = item_similarity_df[item]\n",
        "            rated_items = user_ratings[user_ratings > 0]  # Item yang sudah diberi rating oleh user\n",
        "\n",
        "            weighted_sum = sum(similar_items[rated_items.index] * rated_items)\n",
        "            total_similarity = sum(abs(similar_items[rated_items.index]))\n",
        "\n",
        "            if total_similarity != 0:\n",
        "                predicted_rating = weighted_sum / total_similarity\n",
        "            else:\n",
        "                predicted_rating = 0  # Jika tidak ada kemiripan, beri nilai default (0 atau rata-rata)\n",
        "\n",
        "            predicted_ratings[item] = predicted_rating\n",
        "\n",
        "    return predicted_ratings\n",
        "\n",
        "# Prediksi rating untuk user_id = 173\n",
        "user_id = 173\n",
        "predicted_ratings = predict_ratings(user_id, pivot_df, item_similarity_df)\n",
        "\n",
        "# Konversi hasil prediksi menjadi DataFrame\n",
        "predicted_df = pd.DataFrame(list(predicted_ratings.items()), columns=['title', 'predicted_rating'])\n",
        "\n",
        "# Urutkan berdasarkan prediksi rating tertinggi\n",
        "predicted_df = predicted_df.sort_values(by='predicted_rating', ascending=False)\n",
        "\n",
        "# Tampilkan tabel hasil prediksi\n",
        "print(f\"Predicted Ratings for User {user_id}:\")\n",
        "print(predicted_df.head(10))  # Menampilkan top hasil prediksi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fuf8v4zzpNVO"
      },
      "source": [
        "## Memberikan rekomendasi berdasarkan rating kemiripan pengguna pada item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NavRKfrai4wY"
      },
      "outputs": [],
      "source": [
        "# Rekomendasi memperhatikan pengguna lain\n",
        "def recommend_books(random_book, predicted_ratings, top_n=5):\n",
        "    # Urutkan item berdasarkan prediksi rating tertinggi\n",
        "    recommended_books = sorted(predicted_ratings.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
        "\n",
        "    print(f\"\\nTop {top_n} Recommended Books for User {random_book}:\")\n",
        "    for book, rating in recommended_books:\n",
        "        print(f\"{book}: Predicted Rating = {rating:.2f}\")\n",
        "\n",
        "# Berikan rekomendasi untuk user_id = 173\n",
        "recommend_books(random_book, predicted_ratings, top_n=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAtoY4xLqA59"
      },
      "source": [
        "## Memberikan rekomendasi berdasarkan kemiripan buku yg di cari dengan buku lainnya dalam database\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szRVktGtyR9T"
      },
      "outputs": [],
      "source": [
        "# Memeriksa apakah input_title ada dalam daftar judul buku yang ada\n",
        "if random_book in item_similarity_df.columns:\n",
        "    # Ambil kemiripan buku input dengan semua buku lainnya\n",
        "    similarity_scores = item_similarity_df[random_book]\n",
        "\n",
        "    # Urutkan buku berdasarkan kemiripan tertinggi\n",
        "    recommended_books = similarity_scores.sort_values(ascending=False)\n",
        "\n",
        "    # Buat DataFrame untuk hasil rekomendasi dalam bentuk tabel\n",
        "    recommended_books_df = recommended_books.head(15).reset_index()\n",
        "    recommended_books_df.columns = ['Title', 'Similarity_Score']\n",
        "\n",
        "    # Tampilkan buku yang paling mirip dalam bentuk tabel\n",
        "    print(f\"Top recommended books similar to: {random_book}\")\n",
        "    print(recommended_books_df)\n",
        "else:\n",
        "    print(\"The input title is not available in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnUCiwtaB94m"
      },
      "source": [
        "# 5. NDCG Evalution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ITyClqwsCF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Fungsi untuk menghitung DCG pada peringkat k\n",
        "def dcg_at_k(scores, k):\n",
        "    scores = np.array(scores)[:k]\n",
        "    return np.sum((2**scores - 1) / np.log2(np.arange(2, len(scores) + 2)))\n",
        "\n",
        "# Fungsi untuk menghitung NDCG pada peringkat k\n",
        "def ndcg_at_k(predicted_scores, ideal_scores, k):\n",
        "    dcg = dcg_at_k(predicted_scores, k)\n",
        "    idcg = dcg_at_k(ideal_scores, k)\n",
        "    return dcg / idcg if idcg > 0 else 0\n",
        "\n",
        "# Misalnya buku yang dimasukkan pengguna\n",
        "random_book = 'The Quiet American'\n",
        "\n",
        "# Ambil kemiripan ideal dari similarity_df (kemiripan buku dengan buku yang dimasukkan)\n",
        "ideal_scores = similarity_df[similarity_df['title'] == random_book].sort_values(by='similarity_score', ascending=False)['similarity_score'].values\n",
        "\n",
        "# Ambil prediksi skor dari recommended_books (rekomendasi buku berdasarkan kemiripan)\n",
        "predicted_scores = recommended_books_df[recommended_books_df['Title'] == random_book].sort_values(by='Similarity_Score', ascending=False)['Similarity_Score'].values\n",
        "\n",
        "# Tentukan peringkat k yang diinginkan (misalnya 10)\n",
        "k = 10\n",
        "\n",
        "# Menghitung NDCG\n",
        "ndcg_score = ndcg_at_k(predicted_scores, ideal_scores, k)\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(f\"NDCG@{k}: {ndcg_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsxjaU-T0DHe"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk menghitung RMSE\n",
        "def calculate_rmse(actual_ratings, predicted_ratings):\n",
        "    # Hanya hitung untuk rating yang tersedia di kedua list\n",
        "    mask = actual_ratings > 0  # Hanya rating yang sudah ada\n",
        "    actual_ratings = actual_ratings[mask]\n",
        "    predicted_ratings = predicted_ratings[mask]\n",
        "\n",
        "    # Hitung RMSE\n",
        "    rmse = np.sqrt(np.mean((actual_ratings - predicted_ratings) ** 2))\n",
        "    return rmse\n",
        "\n",
        "# Misalnya, data rating aktual dan prediksi untuk buku tertentu\n",
        "actual_ratings = np.array([4, 5, 3, 0, 2])  # Contoh rating yang diberikan pengguna\n",
        "predicted_ratings = np.array([5, 5, 5, 5, 5])  # Contoh rating prediksi model\n",
        "\n",
        "# Menghitung RMSE\n",
        "rmse_score = calculate_rmse(actual_ratings, predicted_ratings)\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(f\"RMSE: {rmse_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsvlKPyF9Vsv"
      },
      "source": [
        "program dibawah digunakan untuk menampilkan heatmap yang menunjukkan korelasi antara beberapa fitur dalam dataset df, yaitu kolom rating, average_rating, dan original_publication_year. Heatmap ini memberikan gambaran visual mengenai hubungan antar fitur tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "161cCQl3zNpt"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 7))\n",
        "corr_matrix = df[['rating', 'average_rating', 'original_publication_year']].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"YlGnBu\")\n",
        "plt.title('Correlation Heatmap of Ratings')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk9-KNEdzGv8"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Memuat data dari file .pkl\n",
        "user_df = joblib.load('/content/drive/MyDrive/Colab Notebooks/Sisrek/user_df.pkl')\n",
        "cosine_sim_df = joblib.load('/content/drive/MyDrive/Colab Notebooks/Sisrek/cosine_sim_df.pkl')\n",
        "\n",
        "@app.route('/api/recommend', methods=['GET'])\n",
        "def recommend():\n",
        "    # Ambil parameter dari query string\n",
        "    book_title = request.args.get('title', '')\n",
        "    top_n = int(request.args.get('top_n', 10))  # Default 10 rekomendasi\n",
        "\n",
        "    if book_title not in cosine_sim_df.columns:\n",
        "        return jsonify({\"error\": f\"Book '{book_title}' not found in the dataset.\"}), 404\n",
        "\n",
        "    # Menghitung similarity dan mengambil top N\n",
        "    similar_books = cosine_sim_df[book_title].sort_values(ascending=False).head(top_n + 1)\n",
        "    similar_books = similar_books.iloc[1:]  # Hapus buku yang sama dengan input\n",
        "\n",
        "    # Format hasil menjadi JSON\n",
        "    recommendations = [{\"title\": book, \"similarity\": score} for book, score in similar_books.items()]\n",
        "    return jsonify({\"recommendations\": recommendations})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnITna1F41bE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}